{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "import torch\n",
    "from scmg.model.contrastive_embedding import (CellEmbedder, \n",
    "                         embed_standardized_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Dataset\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoencoder model\n",
    "model_ce_path = '../contrastive_embedding/trained_embedder/'\n",
    "\n",
    "model_ce = torch.load(os.path.join(model_ce_path, 'model.pt'))\n",
    "model_ce.load_state_dict(torch.load(os.path.join(model_ce_path, 'best_state_dict.pth')))\n",
    "\n",
    "device = 'cuda:0'\n",
    "model_ce.to(device)\n",
    "model_ce.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input files\n",
    "adata_input_path = '/GPUData_xingjie/SCMG/sc_rna_data/'\n",
    "dataset_names = sorted([f.replace('.h5ad', '') for f in os.listdir(adata_input_path)])\n",
    "\n",
    "standard_gene_df = pd.read_csv(\n",
    "    '/GPUData_xingjie/Softwares/SCMG_dev/scmg/data/standard_genes.csv')\n",
    "standard_ids = list(standard_gene_df['human_id'])\n",
    "\n",
    "# Create the output folder\n",
    "output_path = '/GPUData_xingjie/SCMG/manifold_generator_training'\n",
    "os.makedirs(os.path.join(output_path, 'datasets'), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    'standard_adata_AllenBrain_WB_MM_2023_all',\n",
    "    'standard_adata_Allen_BrainAging_MM_2022_all',\n",
    "    'standard_adata_Arutyunyan_Placenta_HS_2023_all',\n",
    "    'standard_adata_Bhaduri_CtxDev_HS_2021_all',\n",
    "    'standard_adata_Cao_dev_HS_2020_all',\n",
    "    'standard_adata_Conde_Immune_HS_2022_all',\n",
    "    'standard_adata_Cowan_Retina_HS_2020_fovea',\n",
    "    'standard_adata_Cowan_Retina_HS_2020_periphery',\n",
    "    'standard_adata_Deng_CarT_HS_2020_all',\n",
    "    'standard_adata_Elmentaite_intestine_HS_2021_all',\n",
    "    'standard_adata_Enge_Pancrea_HS_2017_all',\n",
    "    'standard_adata_Eraslan_MultiTissue_HS_2022_all',\n",
    "    'standard_adata_Fawkner-Corbett_IntestineDev_HS_2021_all',\n",
    "    'standard_adata_Han_HS_2020_all',\n",
    "    'standard_adata_He_LungDev_HS_2022_all',\n",
    "    'standard_adata_Hrovatin_Pancrea_MM_2022_all',\n",
    "    'standard_adata_Jardine_BloodDev_HS_2021_normal',\n",
    "    'standard_adata_Khaled_Breast_HS_2023_all',\n",
    "    'standard_adata_Kuppe_Heart_HS_2022_all',\n",
    "    'standard_adata_LaManno_WBDev_MM_2021_all',\n",
    "    'standard_adata_Lake_Kidney_HS_2023_all',\n",
    "    'standard_adata_Lengyel_FallopianTube_HS_2022_all',\n",
    "    'standard_adata_Litvinukova_Heart_HS_2020_all',\n",
    "    'standard_adata_Park_Thymus_HS_2020_all',\n",
    "    'standard_adata_Qiu_Organogenesis_MM_2022_all',\n",
    "    'standard_adata_Qiu_whole_embryo_dev_MM_2024_all',\n",
    "    'standard_adata_Sikkema_Lung_HS_2023_core',\n",
    "    'standard_adata_Streets_Adipose_HS_2023_all',\n",
    "    'standard_adata_Suo_ImmuneDev_HS_2022_all',\n",
    "    'standard_adata_Tabula_Muris_MM_2020_10x',\n",
    "    'standard_adata_Tabula_Muris_MM_2020_smart-seq',\n",
    "    'standard_adata_Tabula_Sapiens_HS_2022_all',\n",
    "    'standard_adata_Tyser_Embryo_HS_2021_all',\n",
    "    'standard_adata_VentoTormo_Placenta_HS_2018_all',\n",
    "    'standard_adata_Wiedemann_Skin_HS_2023_all',\n",
    "    'standard_adata_Yanagida_Blastocyst_HS_2021_all',\n",
    "    'standard_adata_Yu_MultiTissue_HS_2021_all'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the cell types considered for the embedder training\n",
    "edge_file_paths = [\n",
    "    '/GPUData_xingjie/SCMG/contrastive_embedding_training/edges/inter_dataset',\n",
    "    '/GPUData_xingjie/SCMG/contrastive_embedding_training/edges/intra_dataset_core',\n",
    "    '/GPUData_xingjie/SCMG/contrastive_embedding_training/edges/intra_integration'\n",
    "]\n",
    "\n",
    "edge_df_list = []\n",
    "\n",
    "for edge_file_path in edge_file_paths:\n",
    "    for f in os.listdir(edge_file_path):\n",
    "        if f.endswith('.parquet'):\n",
    "            edge_df = pd.read_parquet(os.path.join(edge_file_path, f))\n",
    "            edge_df_list.append(edge_df)\n",
    "\n",
    "edge_df = pd.concat(edge_df_list, axis=0)\n",
    "\n",
    "ds_ct_dict = {ds : set() for ds in np.unique(edge_df['dataset_query'])}\n",
    "\n",
    "\n",
    "for i, row in edge_df.iterrows():\n",
    "    ds_ct_dict[row['dataset_query']].add(row['cell_type_query'])\n",
    "    ds_ct_dict[row['dataset_ref']].add(row['cell_type_ref'])\n",
    "\n",
    "import json\n",
    "for ds, cts in ds_ct_dict.items():\n",
    "    ds_ct_dict[ds] = sorted(cts)\n",
    "with open('dataset_cell_types.json', 'w') as f:\n",
    "    f.write(json.dumps(ds_ct_dict))\n",
    "\n",
    "all_cell_types = set()\n",
    "for ds, cts in ds_ct_dict.items():\n",
    "    all_cell_types.update(cts)\n",
    "\n",
    "pd.DataFrame({\n",
    "    'cell_type' : sorted(all_cell_types)\n",
    "}).to_csv('cell_types.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds in ds_ct_dict:\n",
    "    dataset_name = f'standard_adata_{ds}'.replace(':', '_')\n",
    "    if dataset_name not in dataset_names:\n",
    "        continue\n",
    "\n",
    "    print(dataset_name)\n",
    "    adata = sc.read_h5ad(os.path.join(adata_input_path, f'{dataset_name}.h5ad'))\n",
    "    display(adata)\n",
    "\n",
    "    # Choose cell types to keep\n",
    "    adata = adata[adata.obs['cell_type'].isin(ds_ct_dict[ds])]\n",
    "\n",
    "    # Subset to the standard genes\n",
    "    common_genes = np.intersect1d(standard_ids, adata.var['human_gene_id'])\n",
    "    adata = adata[:, adata.var['human_gene_id'].isin(common_genes)].copy()\n",
    "    adata.var.index = adata.var['human_gene_id']\n",
    "    sc.pp.filter_cells(adata, min_genes=100)\n",
    "    display(adata)\n",
    "\n",
    "    # Get the indices of standard genes to save\n",
    "    adata_var_ids = list(adata.var.index)\n",
    "    common_ids = np.intersect1d(standard_ids, adata_var_ids)\n",
    "    common_in_standard_indices = [standard_ids.index(g) for g in common_ids]\n",
    "    common_in_adata_indices = [adata_var_ids.index(g) for g in common_ids]\n",
    "\n",
    "    # Save the data by chunk\n",
    "    chunk_size = 50000\n",
    "    N_cells = adata.shape[0]\n",
    "    N_chunks = int(np.ceil(N_cells / chunk_size))\n",
    "    \n",
    "    for i in range(N_chunks):\n",
    "        start = i * chunk_size\n",
    "        stop = min((i + 1) * chunk_size, N_cells)\n",
    "        n_chunk_cells = stop - start\n",
    "        \n",
    "        # Get tht standardized expressions for the chunk cells and their neighbors\n",
    "        adata_chunk = adata[start:stop].copy()\n",
    "        \n",
    "        # Record which genes are measured in this dataset\n",
    "        X_measure = np.zeros((n_chunk_cells, len(standard_ids)), dtype=bool)\n",
    "        X_measure[:, common_in_standard_indices] = True\n",
    "\n",
    "        # Get the standardized expressions\n",
    "        if scipy.sparse.issparse(adata_chunk.X):\n",
    "            X_chunk = adata_chunk.X.toarray()\n",
    "        else:\n",
    "            X_chunk = adata_chunk.X\n",
    "\n",
    "        X_chunk_standard = np.zeros((X_chunk.shape[0], \n",
    "                        len(standard_ids)), dtype=np.float32)\n",
    "        X_chunk_standard[:, common_in_standard_indices] = X_chunk[:, \n",
    "                                                        common_in_adata_indices]\n",
    "\n",
    "        adata_chunk_standard = anndata.AnnData(X=X_chunk_standard,\n",
    "                                       obs=adata_chunk.obs.copy(),\n",
    "                                       var=pd.DataFrame(index=standard_ids))\n",
    "\n",
    "        # Embed the standardized expressions\n",
    "        embed_standardized_adata(model_ce, adata_chunk_standard, inplace=True)\n",
    "\n",
    "        # Save the dataset\n",
    "        dataset = Dataset.from_dict({\n",
    "                 'X_ce_latent': adata_chunk_standard.obsm['X_ce_latent'],\n",
    "                 'cell_type' : adata_chunk.obs['cell_type'].values,\n",
    "                 })\n",
    "        dataset.save_to_disk(os.path.join(output_path, 'datasets', f'{dataset_name}_{i}'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
