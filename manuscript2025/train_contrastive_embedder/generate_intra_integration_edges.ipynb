{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "sc.settings.n_jobs = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_raw_adata_copy(adata):\n",
    "    adata_raw = adata.copy()\n",
    "    adata_raw.var.index = list(adata_raw.var['human_gene_id'])\n",
    "    adata_raw.var_names_make_unique()\n",
    "    return adata_raw\n",
    "\n",
    "def find_hv_genes(adata_origin):\n",
    "    adata = adata_origin.copy()\n",
    "    sc.pp.filter_cells(adata, min_genes=20)\n",
    "\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, min_mean=0.01, max_mean=10, min_disp=0.3)\n",
    "\n",
    "    return adata.var[adata.var['highly_variable']].index.tolist()\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def mutual_k_nearest_neighbors(arr1, arr2, k):\n",
    "    # Initialize NearestNeighbors models for each array\n",
    "    nn1 = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "    nn2 = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "    \n",
    "    # Fit the models\n",
    "    nn1.fit(arr1)\n",
    "    nn2.fit(arr2)\n",
    "    \n",
    "    # Find K nearest neighbors\n",
    "    distances1, indices1 = nn2.kneighbors(arr1)\n",
    "    distances2, indices2 = nn1.kneighbors(arr2)\n",
    "    \n",
    "    p1s = []\n",
    "    p2s = []\n",
    "    distances = []\n",
    "    \n",
    "    # Iterate over points in arr1\n",
    "    for p1 in range(arr1.shape[0]):\n",
    "        for i in range(k):\n",
    "            p2 = indices1[p1, i]\n",
    "            if p1 in indices2[p2]:\n",
    "                p1s.append(p1)\n",
    "                p2s.append(p2)\n",
    "                distances.append(distances1[p1, i])\n",
    "    \n",
    "    return p1s, p2s, distances\n",
    "\n",
    "def integrate_datasets(adata_ref, adata_query,\n",
    "                       k=30, dist_threshold=0.4):\n",
    "    adata_ref.var.index = list(adata_ref.var['human_gene_id'])\n",
    "    adata_query.var.index = list(adata_query.var['human_gene_id'])\n",
    "    adata_ref.var_names_make_unique()\n",
    "    adata_query.var_names_make_unique()\n",
    "\n",
    "    hvg1 = find_hv_genes(adata_ref)\n",
    "    hvg2 = find_hv_genes(adata_query)\n",
    "\n",
    "    hv_genes = np.intersect1d(hvg1, hvg2)\n",
    "    print(f'Found {len(hv_genes)} highly variable genes in both datasets')\n",
    "\n",
    "    adata_ref = adata_ref[:, hv_genes].copy()\n",
    "    adata_query = adata_query[:, hv_genes].copy()\n",
    "\n",
    "    sc.pp.filter_cells(adata_ref, min_genes=20)\n",
    "    sc.pp.filter_cells(adata_query, min_genes=20)\n",
    "\n",
    "    sc.pp.normalize_total(adata_ref, target_sum=len(hv_genes))\n",
    "    sc.pp.log1p(adata_ref)\n",
    "    sc.pp.scale(adata_ref, max_value=10)\n",
    "\n",
    "    sc.pp.normalize_total(adata_query, target_sum=len(hv_genes))\n",
    "    sc.pp.log1p(adata_query)\n",
    "    sc.pp.scale(adata_query, max_value=10)\n",
    "\n",
    "    adata_merge = anndata.concat(\n",
    "        {'ref': adata_ref, 'query': adata_query},\n",
    "        label='batch_category',\n",
    "    )\n",
    "\n",
    "    # Get the significant PCs\n",
    "    sc.tl.pca(adata_merge, svd_solver='arpack', n_comps=100)\n",
    "\n",
    "    adata_m1 = adata_merge[adata_merge.obs['batch_category'] == 'ref']\n",
    "    adata_m2 = adata_merge[adata_merge.obs['batch_category'] == 'query']\n",
    "\n",
    "    p1s, p2s, distances = mutual_k_nearest_neighbors(adata_m1.obsm['X_pca'], \n",
    "                                         adata_m2.obsm['X_pca'], k=k)\n",
    "    mkn_df = pd.DataFrame({\n",
    "        'cell1': adata_m1.obs.index[p1s],\n",
    "        'cell2': adata_m2.obs.index[p2s],\n",
    "        'dist': distances\n",
    "    }).sort_values('dist')\n",
    "\n",
    "    mkn_df = mkn_df[mkn_df['dist'] < dist_threshold]\n",
    "    print(f'Found {mkn_df.shape[0]} mutual k-nearest neighbors.')\n",
    "\n",
    "    return mkn_df['cell1'].values, mkn_df['cell2'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input files\n",
    "adata_input_path = '/GPUData_xingjie/SCMG/sc_rna_data/'\n",
    "dataset_names = sorted([f.replace('.h5ad', '') for f in os.listdir(adata_input_path)])\n",
    "\n",
    "standard_gene_df = pd.read_csv(\n",
    "    '/GPUData_xingjie/Softwares/SCMG_dev/scmg/data/standard_genes.csv')\n",
    "standard_ids = list(standard_gene_df['human_id'])\n",
    "\n",
    "# Create the output folder\n",
    "output_path = '/GPUData_xingjie/SCMG/contrastive_embedding_training/edges/intra_integration'\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrate the developmental atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all = sc.read_h5ad(os.path.join(adata_input_path, \n",
    "                        'standard_adata_Qiu_Organogenesis_MM_2022_all.h5ad'))\n",
    "adata_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all.obs['development_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_group_pairs = [\n",
    "    (['E5.25', 'E6.25'], ['E3.5', 'E4.5'], 50, 0.6),\n",
    "    (['E6.75'], ['E5.25', 'E6.25'], 20, 0.4),\n",
    "    (['E8.5b'], ['E8', 'E8.25', 'E8.5a'], 10, 0.4),\n",
    "    (['E9.5'], ['E8.5b'], 10, 0.4),\n",
    "]\n",
    "\n",
    "for i, igp in enumerate(integration_group_pairs):\n",
    "\n",
    "    adata1 = adata_all[adata_all.obs['development_stage'].isin(igp[0])]\n",
    "    adata2 = adata_all[adata_all.obs['development_stage'].isin(igp[1])]\n",
    "\n",
    "    #cell_types1 = np.unique(adata1.obs['cell_type'])\n",
    "    #cell_types2 = np.unique(adata2.obs['cell_type'])\n",
    "    #common_cell_types = np.intersect1d(cell_types1, cell_types2)\n",
    "    #adata1 = adata1[adata1.obs['cell_type'].isin(common_cell_types)].copy()\n",
    "    #adata2 = adata2[adata2.obs['cell_type'].isin(common_cell_types)].copy()\n",
    "\n",
    "    # Downsample the datasets if there are too many cells\n",
    "    downsample_frac = 0.2\n",
    "    min_cell_number = 1000\n",
    "    n_obs1 = max(int(adata1.shape[0] * downsample_frac), min_cell_number)\n",
    "    n_obs2 = max(int(adata2.shape[0] * downsample_frac), min_cell_number)\n",
    "\n",
    "    if adata1.shape[0] > n_obs1:\n",
    "        sc.pp.subsample(adata1, n_obs=n_obs1, copy=False)\n",
    "    if adata2.shape[0] > n_obs2:\n",
    "        sc.pp.subsample(adata2, n_obs=n_obs2, copy=False)\n",
    "\n",
    "    display(adata1)\n",
    "    display(adata2)\n",
    "\n",
    "    # Integrateion\n",
    "    adata1_raw = generate_raw_adata_copy(adata1)\n",
    "    adata2_raw = generate_raw_adata_copy(adata2)\n",
    "    anchor_cells1, anchor_cells2 = integrate_datasets(\n",
    "                    adata_ref=adata1, adata_query=adata2,\n",
    "                    k=igp[2], dist_threshold=igp[3])\n",
    "\n",
    "    # Generate contrastive datasets\n",
    "    output_prefix = os.path.join(output_path, \n",
    "                                 f'Qiu_Organogenesis_MM_2022_all_intra_{i}')\n",
    "    \n",
    "    edges_df = pd.DataFrame({\n",
    "        'cell_ref': anchor_cells1,\n",
    "        'cell_query': anchor_cells2,\n",
    "        'dataset_ref': adata1_raw[anchor_cells1].obs['dataset_id'].values,\n",
    "        'dataset_query': adata2_raw[anchor_cells2].obs['dataset_id'].values,\n",
    "        'cell_type_ref': adata1_raw[anchor_cells1].obs['cell_type'].values,\n",
    "        'cell_type_query': adata2_raw[anchor_cells2].obs['cell_type'].values,\n",
    "    })\n",
    "\n",
    "    edges_df.to_parquet(f'{output_prefix}.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intra integration for Suo_ImmuneDev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all = sc.read_h5ad(os.path.join(adata_input_path, \n",
    "                        'standard_adata_Suo_ImmuneDev_HS_2022_all.h5ad'))\n",
    "adata_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(adata_all.obs['cell_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integration_group_pairs = [\n",
    "    (['double negative thymocyte'], ['early lymphoid progenitor'], 5, 2),\n",
    "    (['late pro-B cell'], ['pro-B cell'], 5, 2),\n",
    "    (['small pre-B-II cell', 'large pre-B-II cell'], ['late pro-B cell'], 5, 2),\n",
    "]\n",
    "\n",
    "for i, igp in enumerate(integration_group_pairs):\n",
    "\n",
    "    adata1 = adata_all[adata_all.obs['cell_type'].isin(igp[0])]\n",
    "    adata2 = adata_all[adata_all.obs['cell_type'].isin(igp[1])]\n",
    "\n",
    "    # Downsample the datasets if there are too many cells\n",
    "    display(adata1)\n",
    "    display(adata2)\n",
    "\n",
    "    # Integrateion\n",
    "    adata1_raw = generate_raw_adata_copy(adata1)\n",
    "    adata2_raw = generate_raw_adata_copy(adata2)\n",
    "    anchor_cells1, anchor_cells2 = integrate_datasets(\n",
    "                    adata_ref=adata1, adata_query=adata2,\n",
    "                    k=igp[2], dist_threshold=igp[3])\n",
    "\n",
    "    # Generate contrastive datasets\n",
    "    output_prefix = os.path.join(output_path, \n",
    "                                 f'Suo_ImmuneDev_HS_2022_all_intra_{i}')\n",
    "    \n",
    "    edges_df = pd.DataFrame({\n",
    "        'cell_ref': anchor_cells1,\n",
    "        'cell_query': anchor_cells2,\n",
    "        'dataset_ref': adata1_raw[anchor_cells1].obs['dataset_id'].values,\n",
    "        'dataset_query': adata2_raw[anchor_cells2].obs['dataset_id'].values,\n",
    "        'cell_type_ref': adata1_raw[anchor_cells1].obs['cell_type'].values,\n",
    "        'cell_type_query': adata2_raw[anchor_cells2].obs['cell_type'].values,\n",
    "    })\n",
    "\n",
    "    edges_df.to_parquet(f'{output_prefix}.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
