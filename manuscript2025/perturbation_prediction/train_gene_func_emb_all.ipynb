{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758bfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import anndata\n",
    "import scanpy as sc\n",
    "import umap\n",
    "import scipy.stats\n",
    "\n",
    "import torch\n",
    "\n",
    "from scmg.model.contrastive_embedding import (CellEmbedder,  embed_adata)\n",
    "\n",
    "from scmg.preprocessing.data_standardization import GeneNameMapper\n",
    "gene_name_mapper = GeneNameMapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e04e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"figure.autolayout\"] = False\n",
    "matplotlib.rc('pdf', fonttype=42)\n",
    "plt.rcParams['font.family'] = 'FreeSans'\n",
    "sc.set_figure_params(vector_friendly=True, dpi_save=300)\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f1e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the autoencoder model\n",
    "model_ce_path = '../../contrastive_embedding/trained_embedder/'\n",
    "\n",
    "model_ce = torch.load(os.path.join(model_ce_path, 'model.pt'))\n",
    "model_ce.load_state_dict(torch.load(os.path.join(model_ce_path, 'best_state_dict.pth')))\n",
    "\n",
    "device = 'cuda:0'\n",
    "model_ce.to(device)\n",
    "model_ce.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1596d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pert_data_files = [\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/AdamsonWeissman2016_GSM2406681_10X010.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/FrangiehIzar2021_RNA.h5ad',\n",
    "#    '/GPUData_xingjie/SCMG/perturbation_data/hESC_TF_screen.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/JiangSatija2024_IFNB.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/JiangSatija2024_IFNG.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/JiangSatija2024_INS.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/JiangSatija2024_TGFB.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/JiangSatija2024_TNFA.h5ad',\n",
    "#    '/GPUData_xingjie/SCMG/perturbation_data/Joung_TFScreen_HS_2023.h5ad',\n",
    "#    '/GPUData_xingjie/SCMG/perturbation_data/knockTF_human.h5ad',\n",
    "#    '/GPUData_xingjie/SCMG/perturbation_data/knockTF_mouse.h5ad',\n",
    "    #'/GPUData_xingjie/SCMG/perturbation_data/omnipath.h5ad',\n",
    "#    '/GPUData_xingjie/SCMG/perturbation_data/PertOrg.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/ReplogleWeissman2022_K562_essential.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/ReplogleWeissman2022_K562_gwps.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/ReplogleWeissman2022_rpe1.h5ad',\n",
    "#    '/GPUData_xingjie/SCMG/perturbation_data/TianKampmann2021_CRISPRa.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/perturbation_data/TianKampmann2021_CRISPRi.h5ad',\n",
    "    '/GPUData_xingjie/SCMG/hESC_perturb_seq/pseudo_bulk.h5ad', # Test\n",
    "]\n",
    "\n",
    "adata_pert_list = []\n",
    "for pdf in pert_data_files:\n",
    "    adata_pert_list.append(sc.read_h5ad(pdf))\n",
    "    print(os.path.basename(pdf), adata_pert_list[-1].shape[0])\n",
    "\n",
    "adata_pert = anndata.concat(adata_pert_list, axis=0)\n",
    "adata_pert.var['gene_name'] = adata_pert_list[0].var['gene_name']\n",
    "\n",
    "adata_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pert = adata_pert[adata_pert.obs['perturbation_sign'] == -1].copy()\n",
    "adata_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask out the direct target genes\n",
    "for i in range(adata_pert.shape[0]):\n",
    "    pg = adata_pert.obs['perturbed_gene'].iloc[i]\n",
    "    \n",
    "    if pg in adata_pert.var_names:\n",
    "        adata_pert.X[i, adata_pert.var_names.get_loc(pg)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea335cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pert_ctl = adata_pert.copy()\n",
    "adata_pert_ctl.X = np.exp(adata_pert_ctl.layers['control']) - 1\n",
    "embed_adata(model_ce, adata_pert_ctl, batch_size=8192)\n",
    "\n",
    "adata_pert.obsm['X_ctl_ce_latent'] = adata_pert_ctl.obsm['X_ce_latent']\n",
    "adata_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19407f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_cat_real_pipeline.py\n",
    "# A simple model & training pipeline: categorical + real vector -> real vector\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterable, List, Sequence, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def build_vocab(categories: Iterable) -> Dict:\n",
    "    \"\"\"Map each unique category to a contiguous integer id.\"\"\"\n",
    "    uniq = sorted({c for c in categories})\n",
    "    return {c: i for i, c in enumerate(uniq)}\n",
    "\n",
    "\n",
    "def encode_categories(categories: Iterable, vocab: Dict) -> np.ndarray:\n",
    "    \"\"\"Convert a list of categories to integer ids using the vocab.\"\"\"\n",
    "    return np.array([vocab[c] for c in categories], dtype=np.int64)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset\n",
    "# ----------------------------\n",
    "class CatRealDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects:\n",
    "      cats: list/array of length N (strings/ints), one categorical value per row\n",
    "      X: np.ndarray of shape (N, D_in)    - real-valued features\n",
    "      Y: np.ndarray of shape (N, D_out)   - real-valued targets\n",
    "    \"\"\"\n",
    "    def __init__(self, cats: Sequence, X: np.ndarray, Y: np.ndarray, \n",
    "                Y_mask: np.ndarray,\n",
    "                vocab: Dict = None):\n",
    "        assert len(cats) == len(X) == len(Y), \"cats, X, and Y must have the same length\"\n",
    "        assert X.ndim == 2 and Y.ndim == 2, \"X and Y must be 2D arrays\"\n",
    "\n",
    "        self.vocab = build_vocab(cats) if vocab is None else vocab\n",
    "        self.cats = encode_categories(cats, self.vocab)            # (N,)\n",
    "        self.X = X.astype(np.float32)                               # (N, D_in)\n",
    "        self.Y = Y.astype(np.float32)                               # (N, D_out)\n",
    "        self.Y_mask = Y_mask.astype(np.float32)                     # (N, D_out)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return tensors ready for the model\n",
    "        return (\n",
    "            torch.tensor(self.cats[idx], dtype=torch.long),         # categorical id\n",
    "            torch.tensor(self.X[idx], dtype=torch.float32),         # real input vector\n",
    "            torch.tensor(self.Y[idx], dtype=torch.float32),         # real target vector\n",
    "            torch.tensor(self.Y_mask[idx], dtype=torch.float32),   # real target mask\n",
    "        )\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Model\n",
    "# ----------------------------\n",
    "class CatRealRegressor(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture-of-experts over categorical input:\n",
    "      1) Shared embedding for the category.\n",
    "      2) K linear heads map the embedding -> output vector (experts).\n",
    "      3) A gating MLP consumes the real-valued input and outputs a softmax over heads.\n",
    "      4) Final prediction = weighted sum of the heads with the gate weights.\n",
    "\n",
    "    Args:\n",
    "        num_categories: number of unique categories\n",
    "        real_dim: dimension of real-valued input vector\n",
    "        out_dim: dimension of prediction vector\n",
    "        emb_dim: dimension of category embedding\n",
    "        num_heads: number of expert heads\n",
    "        gate_hidden: hidden size of gating MLP (single hidden layer by default)\n",
    "        dropout: dropout applied on the embedding before experts (optional)\n",
    "        softmax_temp: temperature for the gate softmax (lower -> sharper)\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_categories: int,\n",
    "        real_dim: int,\n",
    "        out_dim: int,\n",
    "        emb_dim: int = 16,\n",
    "        num_heads: int = 8,\n",
    "        gate_hidden: int = 32,\n",
    "        dropout: float = 0.0,\n",
    "        softmax_temp: float = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert num_heads >= 2, \"Use at least 2 heads to benefit from gating.\"\n",
    "\n",
    "        # 1) Category embedding\n",
    "        self.embedding = nn.Embedding(num_embeddings=num_categories, embedding_dim=emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout and dropout > 0 else nn.Identity()\n",
    "\n",
    "        # 2) Expert linear heads (embedding -> out_dim)\n",
    "        self.num_heads = num_heads\n",
    "        self.experts = nn.ModuleList([nn.Linear(emb_dim, out_dim) for _ in range(num_heads)])\n",
    "\n",
    "        # 3) Gating network (real input -> weights over heads)\n",
    "        #    Simple 1-hidden-layer MLP; feel free to deepen if needed.\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(real_dim, gate_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_hidden, num_heads),\n",
    "        )\n",
    "        self.softmax_temp = softmax_temp\n",
    "\n",
    "        # Optional: Initialize experts a bit conservatively\n",
    "        for lin in self.experts:\n",
    "            nn.init.xavier_uniform_(lin.weight)\n",
    "            nn.init.zeros_(lin.bias)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "    def forward(self, cat_idx: torch.Tensor, x_real: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            cat_idx: (B,)  long tensor of category ids\n",
    "            x_real:  (B, real_dim) float tensor\n",
    "        Output:\n",
    "            y_hat:   (B, out_dim) float tensor\n",
    "        \"\"\"\n",
    "        B = cat_idx.size(0)\n",
    "\n",
    "        # Embed category and compute each expert head output\n",
    "        emb = self.dropout(self.embedding(cat_idx))             # (B, emb_dim)\n",
    "        head_outs = []\n",
    "        for k in range(self.num_heads):\n",
    "            yk = self.experts[k](emb)                           # (B, out_dim)\n",
    "            head_outs.append(yk)\n",
    "        H = torch.stack(head_outs, dim=1)                       # (B, num_heads, out_dim)\n",
    "\n",
    "        # Gate weights from real input\n",
    "        gate_logits = self.gate(x_real)                         # (B, num_heads)\n",
    "        if self.softmax_temp != 1.0:\n",
    "            gate_logits = gate_logits / self.softmax_temp\n",
    "        w = torch.softmax(gate_logits, dim=1)                   # (B, num_heads)\n",
    "\n",
    "        # Weighted sum of head outputs\n",
    "        y_hat = torch.sum(H * w.unsqueeze(-1), dim=1)           # (B, out_dim)\n",
    "        return y_hat\n",
    "\n",
    "def _mean_pearson_corr(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-8) -> float:\n",
    "    \"\"\"\n",
    "    Column-wise Pearson r between y_true and y_pred, then mean across columns.\n",
    "    Handles constant columns by treating their correlation as 0.0.\n",
    "    y_true, y_pred: (N, D) arrays\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true, dtype=np.float64)\n",
    "    y_pred = np.asarray(y_pred, dtype=np.float64)\n",
    "\n",
    "    # center\n",
    "    yt = y_true - y_true.mean(axis=0, keepdims=True)\n",
    "    yp = y_pred - y_pred.mean(axis=0, keepdims=True)\n",
    "\n",
    "    # std (avoid divide by zero)\n",
    "    syt = np.sqrt((yt ** 2).sum(axis=0) + eps)\n",
    "    syp = np.sqrt((yp ** 2).sum(axis=0) + eps)\n",
    "\n",
    "    # covariance per column\n",
    "    cov = (yt * yp).sum(axis=0)\n",
    "\n",
    "    r = cov / (syt * syp)           # shape (D,)\n",
    "    r = np.clip(r, -1.0, 1.0)       # numeric safety\n",
    "    # If a column is (near) constant in y_true or y_pred, correlation ~0 (already handled via eps)\n",
    "    return float(np.nanmean(r))\n",
    "\n",
    "# ----------------------------\n",
    "# Training / Evaluation\n",
    "# ----------------------------\n",
    "@dataclass\n",
    "class TrainConfig:\n",
    "    batch_size: int = 128\n",
    "    epochs: int = 20\n",
    "    lr: float = 1e-2\n",
    "    weight_decay: float = 1e-3\n",
    "    val_split: float = 0.0\n",
    "    seed: int = 42\n",
    "    num_workers: int = 0   # set >0 if you want background workers in DataLoader\n",
    "    max_grad_norm: float = 1.0\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    cats: Sequence,\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    Y_mask: np.ndarray,\n",
    "    config: TrainConfig = TrainConfig(),\n",
    "    emb_dim: int = 16,\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Trains the model and returns a dict with: model, vocab, history, and device.\n",
    "    \"\"\"\n",
    "    # Reproducibility\n",
    "    torch.manual_seed(config.seed)\n",
    "    np.random.seed(config.seed)\n",
    "\n",
    "    # Dataset & split\n",
    "    full_ds = CatRealDataset(cats, X, Y, Y_mask)\n",
    "    n_total = len(full_ds)\n",
    "    n_val = int(n_total * config.val_split)\n",
    "    n_train = n_total - n_val\n",
    "\n",
    "    if n_val > 0:\n",
    "        train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=torch.Generator().manual_seed(config.seed))\n",
    "        train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "        val_loader = DataLoader(val_ds, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "    else:\n",
    "        train_loader = DataLoader(full_ds, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "        val_loader = None\n",
    "\n",
    "    # Model\n",
    "    num_categories = len(full_ds.vocab)\n",
    "    real_dim = X.shape[1]\n",
    "    out_dim = Y.shape[1]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = CatRealRegressor(\n",
    "        num_categories=num_categories,\n",
    "        real_dim=real_dim,\n",
    "        out_dim=out_dim,\n",
    "        emb_dim=emb_dim,\n",
    "    ).to(device)\n",
    "\n",
    "    # Loss & Optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "\n",
    "    \n",
    "    history = {\n",
    "        \"train_loss\": [], \"val_loss\": [],\n",
    "        \"val_mae\": [],\n",
    "        \"train_corr\": [], \"val_corr\": []   # <-- new metrics\n",
    "    }\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(1, config.epochs + 1):\n",
    "        model.train()\n",
    "        running = 0.0\n",
    "\n",
    "        # for correlation we need full-epoch preds/targets\n",
    "        train_preds_np = []\n",
    "        train_targets_np = []\n",
    "\n",
    "        for cat_ids, x_real, y, y_mask in train_loader:\n",
    "            cat_ids = cat_ids.to(device)\n",
    "            x_real = x_real.to(device)\n",
    "            y = y.to(device)\n",
    "            y_mask = y_mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(cat_ids, x_real)\n",
    "            loss = criterion(preds * y_mask, y * y_mask)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.max_grad_norm)\n",
    "            optimizer.step()\n",
    "\n",
    "            running += loss.item() * len(x_real)\n",
    "\n",
    "            # collect for corr (detach -> cpu -> numpy)\n",
    "            with torch.no_grad():\n",
    "                train_preds_np.append((preds * y_mask).detach().cpu().numpy())\n",
    "                train_targets_np.append((y * y_mask).detach().cpu().numpy())\n",
    "\n",
    "        train_loss = running / n_train\n",
    "        train_corr = _mean_pearson_corr(np.vstack(train_targets_np), np.vstack(train_preds_np))\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_corr\"].append(train_corr)\n",
    "\n",
    "        # Validation\n",
    "        if val_loader is not None:\n",
    "            model.eval()\n",
    "            val_running = 0.0\n",
    "            val_mae_running = 0.0\n",
    "            val_preds_np = []\n",
    "            val_targets_np = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for cat_ids, x_real, y, y_mask in val_loader:\n",
    "                    cat_ids = cat_ids.to(device)\n",
    "                    x_real = x_real.to(device)\n",
    "                    y = y.to(device)\n",
    "                    y_mask = y_mask.to(device)\n",
    "\n",
    "                    preds = model(cat_ids, x_real)\n",
    "                    loss = criterion(preds * y_mask, y * y_mask)\n",
    "                    mae = torch.mean(torch.abs(preds - y))\n",
    "\n",
    "                    val_running += loss.item() * len(x_real)\n",
    "                    val_mae_running += mae.item() * len(x_real)\n",
    "\n",
    "                    val_preds_np.append((preds * y_mask).detach().cpu().numpy())\n",
    "                    val_targets_np.append((y * y_mask).detach().cpu().numpy())\n",
    "\n",
    "            val_loss = val_running / max(1, n_val)\n",
    "            val_mae = val_mae_running / max(1, n_val)\n",
    "            val_corr = _mean_pearson_corr(np.vstack(val_targets_np), np.vstack(val_preds_np)) if n_val > 0 else float(\"nan\")\n",
    "\n",
    "            history[\"val_loss\"].append(val_loss)\n",
    "            history[\"val_mae\"].append(val_mae)\n",
    "            history[\"val_corr\"].append(val_corr)       # <-- saved\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d} | \"\n",
    "                f\"train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n",
    "                f\"val_MAE={val_mae:.4f} | train_corr={train_corr:.4f} | val_corr={val_corr:.4f}\"\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            print(\n",
    "                f\"Epoch {epoch:02d} | \"\n",
    "                f\"train_loss={train_loss:.4f} | \"\n",
    "                f\"train_corr={train_corr:.4f} | \"\n",
    "            )\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"vocab\": full_ds.vocab,  # category -> id mapping (save this!)\n",
    "        \"history\": history,\n",
    "        \"device\": device,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0547cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pert.obs['condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc77b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adata_train = adata_pert[adata_pert.obs['condition'] == 'ReplogleWeissman2022_K562_gwps'].copy()\n",
    "adata_train = adata_pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4737088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TrainConfig(epochs=100, batch_size=256, lr=1e-2)\n",
    "\n",
    "cats = list(adata_train.obs['perturbed_gene_name'].values)\n",
    "X = adata_train.obsm['X_ctl_ce_latent'].copy()\n",
    "Y = adata_train.X.copy()\n",
    "Y_mask = adata_train.layers['measure_mask'].copy()\n",
    "\n",
    "result = train_model(cats, X, Y, Y_mask, config=cfg, emb_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d42de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history: dict):\n",
    "    \"\"\"\n",
    "    Plot training/validation loss, MAE, and correlation curves.\n",
    "    Expects keys:\n",
    "      - 'train_loss', 'val_loss'\n",
    "      - 'val_mae'\n",
    "      - 'train_corr', 'val_corr'\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(history[\"train_loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(9, 4))\n",
    "\n",
    "    # ---- Loss subplot ----\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    plt.plot(epochs, history[\"train_loss\"], label=\"Train Loss\")\n",
    "    if len(history['train_loss']) == len(history['val_loss']):\n",
    "        plt.plot(epochs, history[\"val_loss\"], label=\"Val Loss\")\n",
    "    \n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"MSE Loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    # ---- Correlation subplot ----\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history[\"train_corr\"], label=\"Train Corr\", color=\"green\")\n",
    "    if len(history['train_loss']) == len(history['val_loss']):\n",
    "        plt.plot(epochs, history[\"val_corr\"], label=\"Val Corr\", color=\"red\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Mean Pearson r\")\n",
    "    plt.title(\"Correlation\")\n",
    "    #plt.ylim(-1.0, 1.0)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "     # ---- MAE subplot ----\n",
    "    if len(history['train_loss']) == len(history['val_loss']):\n",
    "        plt.plot(epochs, history[\"val_mae\"], marker=\"o\", label=\"Val MAE\", color=\"orange\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Mean Absolute Error\")\n",
    "        plt.title(\"Validation MAE\")\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(result['history'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a69c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_embeddings(model, vocab: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract category embeddings as a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        model: trained model that has `embedding` layer\n",
    "        vocab: dict mapping category_name -> id (from dataset)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame of shape (num_categories, emb_dim), \n",
    "        with category names as index.\n",
    "    \"\"\"\n",
    "    # Get weight matrix (num_categories x emb_dim)\n",
    "    emb_matrix = model.embedding.weight.detach().cpu().numpy()\n",
    "    \n",
    "    # Reverse vocab: id -> category\n",
    "    id_to_cat = {i: c for c, i in vocab.items()}\n",
    "    \n",
    "    # Build dataframe\n",
    "    df = pd.DataFrame(\n",
    "        emb_matrix,\n",
    "        index=[id_to_cat[i] for i in range(len(id_to_cat))],\n",
    "        columns=[f\"dim_{j}\" for j in range(emb_matrix.shape[1])]\n",
    "    )\n",
    "    return df\n",
    "\n",
    "emb_df = get_category_embeddings(result[\"model\"], result[\"vocab\"])\n",
    "emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619c0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_df.to_parquet('gene_func_emb_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f44672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "def get_output_feature_embeddings(\n",
    "    model,\n",
    "    out_feature_names: Optional[List[str]] = None,\n",
    "    normalize: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build output-feature embeddings by concatenating the per-expert weight rows.\n",
    "\n",
    "    For each expert k (Linear: out_dim x emb_dim), take row j -> vector in R^{emb_dim}.\n",
    "    Concatenate across all experts to get a vector in R^{emb_dim * num_heads} for output j.\n",
    "\n",
    "    Args:\n",
    "        model: Trained CatRealRegressor with `experts` (ModuleList of Linear layers).\n",
    "        out_feature_names: Optional list of names for outputs (length = out_dim).\n",
    "                           If None, uses ['out_0', ..., 'out_{out_dim-1}'].\n",
    "        normalize: If True, L2-normalize each embedding row after concatenation.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame of shape (out_dim, emb_dim * num_heads), indexed by output names.\n",
    "    \"\"\"\n",
    "    # Grab expert weights as numpy arrays; each W_k has shape (out_dim, emb_dim)\n",
    "    expert_weights = [lin.weight.detach().cpu().numpy() for lin in model.experts]\n",
    "    num_heads = len(expert_weights)\n",
    "    out_dim, emb_dim = expert_weights[0].shape\n",
    "\n",
    "    # Sanity check: consistent shapes across experts\n",
    "    for W in expert_weights[1:]:\n",
    "        assert W.shape == (out_dim, emb_dim), \"All experts must have the same (out_dim, emb_dim).\"\n",
    "\n",
    "    # For each output feature j, collect [W_0[j,:], W_1[j,:], ..., W_{K-1}[j,:]] and concat\n",
    "    rows = []\n",
    "    for j in range(out_dim):\n",
    "        parts = [W[j, :] for W in expert_weights]                   # K x emb_dim\n",
    "        emb = np.concatenate(parts, axis=0)                         # (K*emb_dim,)\n",
    "        if normalize:\n",
    "            norm = np.linalg.norm(emb) + 1e-12\n",
    "            emb = emb / norm\n",
    "        rows.append(emb)\n",
    "\n",
    "    # Build column names for interpretability: head_k.dim_d\n",
    "    col_names = [f\"head_{k}.dim_{d}\" for k in range(num_heads) for d in range(emb_dim)]\n",
    "\n",
    "    # Output names\n",
    "    if out_feature_names is None:\n",
    "        out_feature_names = [f\"out_{j}\" for j in range(out_dim)]\n",
    "    else:\n",
    "        assert len(out_feature_names) == out_dim, \"out_feature_names length must match out_dim.\"\n",
    "\n",
    "    df = pd.DataFrame(rows, index=out_feature_names, columns=col_names)\n",
    "    return df\n",
    "\n",
    "out_emb_df = get_output_feature_embeddings(result[\"model\"], out_feature_names=list(adata_pert.var.index), normalize=False)\n",
    "out_emb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56de322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_emb_df.to_parquet('gene_readout_emb_all.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d71101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scmg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
